{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCCIÓN"
      ],
      "metadata": {
        "id": "j5vcMcPdgH_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "7yZXuXzkhEdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANÁLISIS EXPLORATORIO DE DATOS (EDA)"
      ],
      "metadata": {
        "id": "OVpt-FYCgIuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([pd.DataFrame(X_num), pd.DataFrame(X_cat).replace('nan', np.nan)], axis=1)\n",
        "df.columns = [f\"attr{i}\" for i in range(10)]\n",
        "df.isna().sum(axis=0)\n",
        "\n",
        "# Partición en entrenamiento y test.\n",
        "X_train, X_test = train_test_split(df, random_state=0)\n",
        "\n",
        "# Procesamiento de valores numéricos.\n",
        "features_num = [f\"attr{i}\" for i in range(7)]\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "pipeline_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Procesamiento de valores categóricos.\n",
        "features_cat = [f\"attr{i}\" for i in range(7, 10)]\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "pipeline_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_cat)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pre-procesador \"global\".\n",
        "# Dependiendo del tipo de columna se aplica una transformación u otra.\n",
        "processor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", pipeline_num, features_num),\n",
        "        (\"cat\", pipeline_cat, features_cat),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Realizamos la transformación.\n",
        "X_train_processed = processor.fit_transform(X_train)\n",
        "X_test_processed = processor.transform(X_test)"
      ],
      "metadata": {
        "id": "PBPlTzkchEvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTICIÓN DE LOS DATOS"
      ],
      "metadata": {
        "id": "O1rpqNA4gRR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "# Vamos a comenzar realizando una división train/test \"normal\".\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "# Comprobemos ahora la distribución de las clases.\n",
        "n_pos_pct = N_SAMPLES_POS / (N_SAMPLES_POS + N_SAMPLES_NEG)\n",
        "n_pos_train_pct = np.sum(y_train) / len(y_train)\n",
        "n_pos_test_pct = np.sum(y_test) / len(y_test)\n",
        "\n",
        "\n",
        " Ahora realizaremos una división estratificada.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)\n",
        "\n",
        "# Comprobemos ahora la distribución de las clases.\n",
        "n_pos_pct = N_SAMPLES_POS / (N_SAMPLES_POS + N_SAMPLES_NEG)\n",
        "n_pos_train_pct = np.sum(y_train) / len(y_train)\n",
        "n_pos_test_pct = np.sum(y_test) / len(y_test)\n",
        "\n",
        "print(f\"Hay un {100 * n_pos_train_pct:.1f} % de instancias positivas en train.\")\n",
        "print(f\"Hay un {100 * n_pos_test_pct:.1f} % de instancias positivas en test.\")\n",
        "print(f\"Hay un {100 * n_pos_pct:.1f} % de instancias positivas en total.\")\n",
        "\n",
        "\n",
        "# Ahora vamos a realizar un proceso de validación cruzada estratificada.\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "n_fold = 1\n",
        "for train_ix, test_ix in cv.split(X_train, y_train):\n",
        "  y_train_train = y_train[train_ix]\n",
        "  y_train_test = y_train[test_ix]\n",
        "  n_pos_traintrain_pct = np.sum(y_train_train) / len(y_train_train)\n",
        "  n_pos_traintest_pct = np.sum(y_train_test) / len(y_train_test)\n",
        "  print(f\"FOLD {n_fold}:\")\n",
        "  print(f\"Hay un {100 * n_pos_traintrain_pct:.1f} % de instancias positivas en train-train.\")\n",
        "  print(f\"Hay un {100 * n_pos_traintest_pct:.1f} % de instancias positivas en train-test.\")\n",
        "  n_fold += 1"
      ],
      "metadata": {
        "id": "_5kyIyTRhFJq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONSTRUCCIÓN DE LOS MODELOS"
      ],
      "metadata": {
        "id": "o-W7S4CCgjXC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8EPQYeVhFgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "ANK9bN86g9ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAJ3XNcEhGPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOOSTING"
      ],
      "metadata": {
        "id": "7IDlyiXShA_b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsVA8PP0hG08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿SE PUEDEN MEJORAR LOS DATOS?"
      ],
      "metadata": {
        "id": "RFfF2omhgmEB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SD_VtT5PhHVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "GAViNe_Kg5lx"
      }
    }
  ]
}